import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error

def evaluar_modelo(modelo, X_test, y_test):
    """
    Eval√∫a el modelo LSTM sobre los datos de prueba.
    Calcula m√©tricas de error y genera un gr√°fico comparando valores reales vs. predichos.
    """
    # Evaluaci√≥n directa
    loss = modelo.evaluate(X_test, y_test, verbose=0)
    print(f"üìâ P√©rdida (MSE) en test: {loss:.4f}")

    # Predicciones
    y_pred = modelo.predict(X_test)

    # M√©tricas
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    print(f"‚úÖ RMSE: {rmse:.4f}")
    print(f"‚úÖ MAE:  {mae:.4f}")

    # Gr√°fico comparativo
    plt.figure(figsize=(12, 5))
    plt.plot(y_test, label='Real', color='steelblue')
    plt.plot(y_pred, label='Predicho', color='orange')
    plt.title('Comparaci√≥n entre valores reales y predichos')
    plt.xlabel('√çndice de muestra')
    plt.ylabel('Consumo normalizado')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("grafico_evaluacion.png")
    print("üìä Gr√°fico guardado como 'grafico_evaluacion.png'.")

    return rmse, mae
